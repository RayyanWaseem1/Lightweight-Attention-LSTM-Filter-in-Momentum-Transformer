{
  "batch_size": 256,
  "dropout": 0.31734041461922524,
  "hidden_dim": 32,
  "learning_rate": 0.00016733234421474757,
  "lstm_dropout": 0.15704206056784661,
  "lstm_num_layers": 1,
  "num_attention_heads": 4,
  "num_epochs": 15,
  "num_transformer_layers": 1,
  "weight_decay": 0.00018670359836023682,
  "weight_dropout": 0.12236291558413373,
  "weight_hidden_dim": 32
}