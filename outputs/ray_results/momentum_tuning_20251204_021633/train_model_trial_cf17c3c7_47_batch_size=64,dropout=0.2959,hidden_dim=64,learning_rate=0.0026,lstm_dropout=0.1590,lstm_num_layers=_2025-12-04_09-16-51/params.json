{
  "batch_size": 64,
  "dropout": 0.2958557280737292,
  "hidden_dim": 64,
  "learning_rate": 0.002620700928523652,
  "lstm_dropout": 0.15897218713979894,
  "lstm_num_layers": 1,
  "num_attention_heads": 4,
  "num_epochs": 15,
  "num_transformer_layers": 2,
  "weight_decay": 2.7760114651617344e-05,
  "weight_dropout": 0.29939065745770943,
  "weight_hidden_dim": 16
}