{
  "batch_size": 64,
  "dropout": 0.13787148543207248,
  "hidden_dim": 64,
  "learning_rate": 0.0024747213208101233,
  "lstm_dropout": 0.16738065448067938,
  "lstm_num_layers": 1,
  "num_attention_heads": 8,
  "num_epochs": 15,
  "num_transformer_layers": 1,
  "weight_decay": 1.0597185086915094e-06,
  "weight_dropout": 0.25970500631422916,
  "weight_hidden_dim": 16
}