{
  "batch_size": 128,
  "dropout": 0.38233490870160197,
  "hidden_dim": 128,
  "learning_rate": 0.0010512287958238614,
  "lstm_dropout": 0.19297451059566448,
  "lstm_num_layers": 1,
  "num_attention_heads": 2,
  "num_epochs": 15,
  "num_transformer_layers": 3,
  "weight_decay": 0.0002654951743150479,
  "weight_dropout": 0.16355793082287792,
  "weight_hidden_dim": 16
}